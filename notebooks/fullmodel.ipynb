{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bf22137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import webdataset as wds\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms \n",
    "import os\n",
    "import random\n",
    "\n",
    "PATH_TO_DATA = \"/mnt/analysis/analysis/rand_sharded_data/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aff9fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_normalize = transforms.Normalize(\n",
    "                  mean=[0.17960437768666657, 0.14584139607643212, 0.10744440357398845, 0.2583671063835548],\n",
    "                  std=[0.059635202669355195, 0.04059554002618016, 0.03371736326989986, 0.06295501902505744]\n",
    ")\n",
    "\n",
    "forcing_normalize = transforms.Normalize(\n",
    "                  mean=[444.9605606256559, 991.7980623653417, 0.00039606951184754176, 96111.04161525163, 0.006652783216819315, 314.3219695851273, 2.82168247768119],\n",
    "                  std=[5.5216369223813535, 12.951212256256913, 0.0002824274832735609, 975.3770569179914, 0.00012386107613000674, 0.6004463118907452, 0.34279194598853185]\n",
    ")\n",
    "\n",
    "forcing_mean = torch.from_numpy(np.array([444.9605606256559, 991.7980623653417, 0.00039606951184754176, 96111.04161525163, 0.006652783216819315, 314.3219695851273, 2.82168247768119]))\n",
    "forcing_std = torch.from_numpy(np.array([5.5216369223813535, 12.951212256256913, 0.0002824274832735609, 975.3770569179914, 0.00012386107613000674, 0.6004463118907452, 0.34279194598853185]))\n",
    "\n",
    "lst_mean = torch.from_numpy(np.array([312.8291360088677]))\n",
    "lst_std = torch.from_numpy(np.array([11.376636496297289]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b37c9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(path_to_data, train_perc, test_perc):\n",
    "    files = []\n",
    "    for dirpath, dirnames, filenames in os.walk(path_to_data):\n",
    "        files.extend(filenames)\n",
    "    \n",
    "    saturated = files[:-1]\n",
    "    unsaturated = files[-1]\n",
    "    \n",
    "    dataset = wds.WebDataset(path_to_data + \"/\" + unsaturated)\n",
    "    counter = 0\n",
    "    for data in dataset:\n",
    "        counter += 1\n",
    "    \n",
    "    total_files = counter + len(saturated) * 10000\n",
    "    training_data = total_files * train_perc //10000\n",
    "    test_data_files = total_files * test_perc //10000\n",
    "\n",
    "    training_data = random.sample(files, int(training_data))\n",
    "    test_data = [file for file in files if file not in training_data]\n",
    "    test_data = random.sample(test_data, int(test_data_files))\n",
    "    # Get sample sizes of train and test data\n",
    "    training_samples = 0\n",
    "    testing_samples = 0\n",
    "    \n",
    "    for path in training_data:\n",
    "        if path in saturated:\n",
    "            training_samples += 10000\n",
    "        elif path in unsaturated:\n",
    "            training_samples += counter\n",
    "            \n",
    "    for path in test_data:\n",
    "        if path in saturated:\n",
    "            testing_samples += 10000\n",
    "        elif path in unsaturated:\n",
    "            testing_samples += counter\n",
    "            \n",
    "            \n",
    "    # Convert to filename lists \n",
    "    training_filepath = []\n",
    "    for dat in training_data:\n",
    "        training_filepath.append(dat[6:12])\n",
    "    training_path = path_to_data + \"shard-\" + \"{\" + \",\".join(training_filepath) + \"}\" + \".tar\"\n",
    "    \n",
    "    testing_filepath = []\n",
    "    for dat in test_data:\n",
    "        testing_filepath.append(dat[6:12])\n",
    "    testing_path = path_to_data + \"shard-{\" + \",\".join(testing_filepath) +\"}.tar\"\n",
    "    train_data = wds.WebDataset(training_path).shuffle(10000, initial=10000).decode(\"rgb\").rename(image=\"image.pyd\", forcing=\"forcing.pyd\", lst = \"lst.pyd\").to_tuple(\"image\", \"forcing\", \"lst\")\n",
    "    test_data = wds.WebDataset(testing_path).decode(\"rgb\").shuffle(10000, initial=10000).rename(image=\"image.pyd\", forcing=\"forcing.pyd\", lst = \"lst.pyd\").to_tuple(\"image\", \"forcing\", \"lst\")\n",
    "            \n",
    "    return (train_data, training_samples), (test_data, testing_samples)\n",
    "    \n",
    "(train_data, training_samples_len), (test_data, testing_samples_len) = create_train_test(PATH_TO_DATA, 0.85, 0.15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92291d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTModel(nn.Module):\n",
    "    def __init__(self, input_shape=(4,33,33), forcing_shape=(1,7)):\n",
    "        super(LSTModel, self).__init__()\n",
    "        self.in_channels = input_shape[0]\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=self.in_channels, out_channels=8, kernel_size=(3,3))\n",
    "        self.conv1_bn = nn.BatchNorm2d(8)\n",
    "        self.mp1 = nn.AvgPool2d(kernel_size=(3,3), stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3,3))\n",
    "        self.conv2_bn = nn.BatchNorm2d(16)\n",
    "        self.mp2 = nn.AvgPool2d(kernel_size=(3, 3), stride=2)\n",
    "#         self.conv3 = nn.Conv2d(in_channels=16, out_channels=8, kernel_size=(1, 1))\n",
    "#         self.conv3_bn = nn.BatchNorm2d(8)\n",
    "\n",
    "        self.flatten_shape = None\n",
    "        zero_ex = torch.zeros(input_shape).unsqueeze(0)\n",
    "        zero_forcing = torch.zeros(forcing_shape)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            self.convolutions(zero_ex, zero_forcing)\n",
    "        \n",
    "        print(self.flatten_shape)\n",
    "        self.fc1 = nn.Linear(in_features=self.flatten_shape, out_features=128)\n",
    "        self.fc_bn1 = nn.BatchNorm1d(128)\n",
    "        self.drop1 = nn.Dropout(0)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=64)\n",
    "        self.fc_bn2 = nn.BatchNorm1d(64)\n",
    "        self.drop2 = nn.Dropout(0)\n",
    "        self.fc3 = nn.Linear(in_features=64, out_features=1)\n",
    "#         self.drop3 = nn.Dropout(0)\n",
    "#         self.fc4 = nn.Linear(in_features=64, out_features=1)\n",
    "        \n",
    "    def convolutions(self, x, forcing):\n",
    "        x = F.leaky_relu(self.conv1_bn(self.conv1(x)))\n",
    "        x = self.mp1(x)\n",
    "        x = F.leaky_relu(self.conv2_bn(self.conv2(x)))\n",
    "        x = self.mp2(x)\n",
    "#         x = F.leaky_relu(self.conv3_bn(self.conv3(x)))\n",
    "#         x = self.mp3(x)\n",
    "\n",
    "        # Reshape for linear\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = torch.cat((x, forcing), dim=1)\n",
    "\n",
    "        if self.flatten_shape is None:\n",
    "            self.flatten_shape = x.shape[1]\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x, forcing):\n",
    "        x = self.convolutions(x, forcing)\n",
    "        x = F.leaky_relu(self.fc_bn1(self.fc1(x)))\n",
    "        x = self.drop1(x)\n",
    "        x = F.leaky_relu(self.fc_bn2(self.fc2(x)))\n",
    "        x = self.drop2(x)\n",
    "        x = self.fc3(x)\n",
    "#         x = self.drop3(x)\n",
    "#         x = self.fc4(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93bbb461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583\n",
      "****** EPOCH: [0/100] LR: 5e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [03:28,  8.22it/s, train_loss=272]                                                                                                             \n",
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model\n",
      "------ Train Loss: 298.96240195158487, Test Loss: 272.1613964281584 ------\n",
      "****** EPOCH: [1/100] LR: 5e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [03:29,  8.18it/s, train_loss=8.02]                                                                                                            \n",
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model\n",
      "------ Train Loss: 141.9150059189752, Test Loss: 7.4343852777230115 ------\n",
      "****** EPOCH: [2/100] LR: 4.9e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [03:29,  8.17it/s, train_loss=6.51]                                                                                                            \n",
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model\n",
      "------ Train Loss: 6.924757671411906, Test Loss: 6.493235719831366 ------\n",
      "****** EPOCH: [3/100] LR: 4.9e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [03:27,  8.23it/s, train_loss=6.27]                                                                                                            \n",
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model\n",
      "------ Train Loss: 6.387936550044568, Test Loss: 6.232335081225948 ------\n",
      "****** EPOCH: [4/100] LR: 4.8e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [03:31,  8.09it/s, train_loss=5.97]                                                                                                            \n",
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model\n",
      "------ Train Loss: 6.120662716783095, Test Loss: 6.011028804277119 ------\n",
      "****** EPOCH: [5/100] LR: 4.8e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [03:28,  8.23it/s, train_loss=5.83]                                                                                                            \n",
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model\n",
      "------ Train Loss: 5.922310895173349, Test Loss: 5.88211945012996 ------\n",
      "****** EPOCH: [6/100] LR: 4.7e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [03:30,  8.15it/s, train_loss=5.73]                                                                                                            \n",
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model\n",
      "------ Train Loss: 5.777873745031446, Test Loss: 5.766486004779213 ------\n",
      "****** EPOCH: [7/100] LR: 4.7e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [03:25,  8.33it/s, train_loss=5.65]                                                                                                            \n",
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model\n",
      "------ Train Loss: 5.668835065910749, Test Loss: 5.683059919821589 ------\n",
      "****** EPOCH: [8/100] LR: 4.6e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [03:29,  8.18it/s, train_loss=5.58]                                                                                                            \n",
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model\n",
      "------ Train Loss: 5.581489594183235, Test Loss: 5.595777580612584 ------\n",
      "****** EPOCH: [9/100] LR: 4.6e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [03:27,  8.23it/s, train_loss=5.52]                                                                                                            \n",
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model\n",
      "------ Train Loss: 5.505761544002551, Test Loss: 5.5238101043199235 ------\n",
      "****** EPOCH: [10/100] LR: 4.5e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [03:28,  8.23it/s, train_loss=5.45]                                                                                                            \n",
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model\n",
      "------ Train Loss: 5.435730120846045, Test Loss: 5.445756400886335 ------\n",
      "****** EPOCH: [11/100] LR: 4.5e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [03:29,  8.16it/s, train_loss=5.29]                                                                                                            \n",
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model\n",
      "------ Train Loss: 5.36952701795881, Test Loss: 5.374665831264696 ------\n",
      "****** EPOCH: [12/100] LR: 4.4e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [03:28,  8.20it/s, train_loss=5.17]                                                                                                            \n",
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model\n",
      "------ Train Loss: 5.303414386566554, Test Loss: 5.365933021432475 ------\n",
      "****** EPOCH: [13/100] LR: 4.4e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [03:31,  8.08it/s, train_loss=5.11]                                                                                                            \n",
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model\n",
      "------ Train Loss: 5.24608706926631, Test Loss: 5.319542269957693 ------\n",
      "****** EPOCH: [14/100] LR: 4.3e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [03:28,  8.20it/s, train_loss=5.02]                                                                                                            \n",
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model\n",
      "------ Train Loss: 5.195962969944856, Test Loss: 5.254260187086306 ------\n",
      "****** EPOCH: [15/100] LR: 4.3e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [03:30,  8.13it/s, train_loss=4.96]                                                                                                            \n",
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model\n",
      "------ Train Loss: 5.15020373825715, Test Loss: 5.229199589867341 ------\n",
      "****** EPOCH: [16/100] LR: 4.3e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [03:29,  8.15it/s, train_loss=5]                                                                                                               \n",
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model\n",
      "------ Train Loss: 5.115896579261138, Test Loss: 5.223089720073499 ------\n",
      "****** EPOCH: [17/100] LR: 4.2e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [03:32,  8.07it/s, train_loss=4.95]                                                                                                            \n",
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Train Loss: 5.082170468624507, Test Loss: 5.235560297966003 ------\n",
      "****** EPOCH: [18/100] LR: 4.2e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [03:32,  8.07it/s, train_loss=4.9]                                                                                                             \n",
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model\n",
      "------ Train Loss: 5.050291481976197, Test Loss: 5.21128047610584 ------\n",
      "****** EPOCH: [19/100] LR: 4.1e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [03:30,  8.13it/s, train_loss=4.84]                                                                                                            \n",
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model\n",
      "------ Train Loss: 5.026738352586176, Test Loss: 5.173607060783787 ------\n",
      "****** EPOCH: [20/100] LR: 4.1e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [03:32,  8.04it/s, train_loss=4.8]                                                                                                             \n",
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model\n",
      "------ Train Loss: 5.004080455993938, Test Loss: 5.173250631282204 ------\n",
      "****** EPOCH: [21/100] LR: 4e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [03:28,  8.22it/s, train_loss=4.82]                                                                                                            \n",
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model\n",
      "------ Train Loss: 4.982053536678029, Test Loss: 5.131355083302448 ------\n",
      "****** EPOCH: [22/100] LR: 4e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [03:30,  8.13it/s, train_loss=4.8]                                                                                                             \n",
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model\n",
      "------ Train Loss: 4.958767231101188, Test Loss: 5.110552938360917 ------\n",
      "****** EPOCH: [23/100] LR: 4e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [03:29,  8.17it/s, train_loss=4.74]                                                                                                            \n",
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Train Loss: 4.9385502550089475, Test Loss: 5.122343599796295 ------\n",
      "****** EPOCH: [24/100] LR: 3.9e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [03:30,  8.14it/s, train_loss=4.77]                                                                                                            \n",
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model\n",
      "------ Train Loss: 4.924228936712319, Test Loss: 5.025449159898256 ------\n",
      "****** EPOCH: [25/100] LR: 3.9e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [03:29,  8.19it/s, train_loss=4.74]                                                                                                            \n",
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Train Loss: 4.909580896112407, Test Loss: 5.036782885852613 ------\n",
      "****** EPOCH: [26/100] LR: 3.9e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [03:29,  8.18it/s, train_loss=4.72]                                                                                                            \n",
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model\n",
      "------ Train Loss: 4.892680312428519, Test Loss: 5.024973074072285 ------\n",
      "****** EPOCH: [27/100] LR: 3.8e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [03:26,  8.27it/s, train_loss=4.7]                                                                                                             \n",
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model\n",
      "------ Train Loss: 4.878425622933379, Test Loss: 4.994588897416466 ------\n",
      "****** EPOCH: [28/100] LR: 3.8e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [03:29,  8.16it/s, train_loss=4.68]                                                                                                            \n",
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Train Loss: 4.8661311201960125, Test Loss: 5.012897125984493 ------\n",
      "****** EPOCH: [29/100] LR: 3.7e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [03:28,  8.21it/s, train_loss=4.65]                                                                                                            \n",
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Train Loss: 4.853950182411158, Test Loss: 5.015660715730567 ------\n",
      "****** EPOCH: [30/100] LR: 3.7e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [03:30,  8.14it/s, train_loss=4.65]                                                                                                            \n",
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Train Loss: 4.8448568120181, Test Loss: 4.996561219817714 ------\n",
      "****** EPOCH: [31/100] LR: 3.7e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [03:31,  8.11it/s, train_loss=4.66]                                                                                                            \n",
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model\n",
      "------ Train Loss: 4.831676854151431, Test Loss: 4.946368085710626 ------\n",
      "****** EPOCH: [32/100] LR: 3.6e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [03:30,  8.15it/s, train_loss=4.63]                                                                                                            \n",
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Model\n",
      "------ Train Loss: 4.8172742245353275, Test Loss: 4.939218047418092 ------\n",
      "****** EPOCH: [33/100] LR: 3.6e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [03:31,  8.11it/s, train_loss=4.62]                                                                                                            \n",
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Train Loss: 4.809630365711507, Test Loss: 4.940231050315656 ------\n",
      "****** EPOCH: [34/100] LR: 3.6e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [03:30,  8.15it/s, train_loss=4.62]                                                                                                            \n",
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Train Loss: 4.7995239980866975, Test Loss: 5.014884162890284 ------\n",
      "****** EPOCH: [35/100] LR: 3.5e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1712it [03:30,  8.15it/s, train_loss=4.6]                                                                                                             \n",
      "                                                                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Train Loss: 4.7903916298229, Test Loss: 4.975357720726414 ------\n",
      "****** EPOCH: [36/100] LR: 3.5e-05 ******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████████████████████████████████████████████████████████████▌                             | 1163/1710 [02:28<01:09,  7.83it/s, train_loss=4.37]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1251324/2267302327.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mloop_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_samples_len\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforcing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforcing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforcing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.9/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.9/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/research/lib/python3.9/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 0.00005\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, num_workers=6)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, num_workers=6)\n",
    "\n",
    "model = LSTModel().to(DEVICE)\n",
    "model = torch.nn.DataParallel(model, device_ids=[0,1])\n",
    "loss_fn = nn.SmoothL1Loss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.95)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n",
    "scheduler2 = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \"min\")\n",
    "# scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.0001, max_lr=0.0005)\n",
    "test_loss = []\n",
    "train_loss = []\n",
    "\n",
    "lst_mean = lst_mean.to(DEVICE)\n",
    "lst_std = lst_std.to(DEVICE)\n",
    "forcing_mean = forcing_mean.to(DEVICE)\n",
    "forcing_std = forcing_std.to(DEVICE)\n",
    "\n",
    "def process_data(image, forcing, lst):\n",
    "    image, forcing, lst = image.to(torch.float32).to(DEVICE), forcing.to(DEVICE), lst.to(DEVICE)\n",
    "    # Image Transformations\n",
    "    image = torch.clip(image, min=0, max=1)\n",
    "#     image = image_normalize(image)\n",
    "    # Forcing Transformation\n",
    "    forcing = torch.div(torch.sub(forcing, forcing_mean), forcing_std).to(torch.float32)\n",
    "    # LST Transformation\n",
    "#     lst = torch.div(torch.sub(lst, lst_mean), lst_std).to(torch.float32).view(-1, 1)\n",
    "    lst = lst.view(-1, 1).to(torch.float32)\n",
    "    return image, forcing, lst\n",
    "\n",
    "min_test_loss = np.inf    \n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"****** EPOCH: [{}/{}] LR: {} ******\".format(epoch, EPOCHS, round(optimizer.param_groups[0]['lr'], 6)))\n",
    "    running_train_loss = 0\n",
    "    train_n_iter = 0\n",
    "    running_test_loss = 0\n",
    "    test_n_iter = 0\n",
    "    \n",
    "    loop_train = tqdm(train_loader, total=(training_samples_len//BATCH_SIZE) + 1, leave=True)\n",
    "    for idx, (image, forcing, lst) in enumerate(loop_train):\n",
    "        image, forcing, lst = process_data(image, forcing, lst)\n",
    "        optimizer.zero_grad()\n",
    "        forward_out = model.forward(image, forcing)\n",
    "        loss = loss_fn(forward_out, lst)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_train_loss += loss.item()\n",
    "        train_n_iter += 1\n",
    "        loop_train.set_postfix(train_loss=loss.item())\n",
    "        \n",
    "    loop_test = tqdm(test_loader, total=(testing_samples_len//BATCH_SIZE) + 1, leave=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, (image, forcing, lst) in enumerate(loop_test):\n",
    "            image, forcing, lst = process_data(image, forcing, lst)\n",
    "            pred = model.forward(image, forcing)\n",
    "            testloss = loss_fn(pred, lst)\n",
    "            running_test_loss += testloss.item()\n",
    "            test_n_iter += 1\n",
    "            loop_test.set_postfix(test_loss=testloss.item())\n",
    "\n",
    "    avg_train_loss = running_train_loss/train_n_iter\n",
    "    train_loss.append(avg_train_loss)\n",
    "    avg_test_loss = running_test_loss/test_n_iter\n",
    "    test_loss.append(avg_test_loss)\n",
    "    \n",
    "    scheduler.step()\n",
    "    scheduler2.step(avg_test_loss)\n",
    "    if avg_test_loss < min_test_loss:\n",
    "        print(\"Saving Model\")\n",
    "        min_test_loss = avg_test_loss\n",
    "        torch.save(model.state_dict(), \"lstmodel.pt\")\n",
    "    print(\"------ Train Loss: {}, Test Loss: {} ------\".format(avg_train_loss, avg_test_loss))\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb682bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plot lines\n",
    "plt.plot(list(range(0,36)), train_loss, label = \"train_loss\")\n",
    "plt.plot(list(range(0,36)), test_loss, label = \"test_loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training Error LST Prediction\")\n",
    "plt.savefig(\"Training Curve.png\")\n",
    "plt.ylim([0, 10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4871f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
