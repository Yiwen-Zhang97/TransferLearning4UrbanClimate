{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "846dcff1",
   "metadata": {},
   "source": [
    "# Preprocess Landsat and MODIS Data\n",
    "\n",
    "This notebook preprocesses datasets from Landsat and MODIS, respectively. Data is from Google Earth Engine, processed, and stored as TFRecord in Google Drive, through the following steps:\n",
    "\n",
    "1. Load city data\n",
    "\n",
    "Only US cities are included at this moment. The data is from the 2020 US Census Bureau's [TIGER/Line Shapefiles](https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html). \n",
    "\n",
    "2. Prepare Landsat data\n",
    "\n",
    "Data ranges from 2003-present.\n",
    "\n",
    "Landsat 7: collection 2 level 2 tier 1 surface reflectance data.\n",
    "(Try using both two consecutive months and two same months from consecutive years.)\n",
    "\n",
    "SLC gap fill:\n",
    "Apply the USGS L7 Phase-2 Gap filling protocol, using a single kernel size. \n",
    "\n",
    "3. Load Modis data\n",
    "\n",
    "Data ranges from 2003-present.\n",
    "\n",
    "Reproject Modis to Landsat projection.\n",
    "\n",
    "Aqua data.LST_Day_1km.\n",
    "\n",
    "4. Download Data in TFRecord Format to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "917cdab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################## Import libraries ######################################################\n",
    "import ee\n",
    "import geemap\n",
    "import sys\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import datetime\n",
    "from dateutil.relativedelta import *\n",
    "from gee_prep import filter_collection, rescale_rename_landsat, export_to_drive, get_gap_filled_image, preprocess_modis\n",
    "from gee_prep import preprocess_modis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc68215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "364c11b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################### Define variables #####################################################\n",
    "drive_folder = 'Data_TFRecord_Daily'\n",
    "landsat_collection = 'LANDSAT/LE07/C02/T1_L2'\n",
    "modis_collection = 'MODIS/061/MYD11A1'\n",
    "us_city_collection = 'users/yiwenz9/us_cities'\n",
    "city_name, city_num = ['Phoenix', 'Phoenix--Mesa, AZ']\n",
    "predictors = ['Blue','Green','Red','NIR','SWIR1','SWIR2','ST']\n",
    "#Preserve only the qa bands of most important images used to fill gaps.\n",
    "qa_bands = ['source_mask', 'qa_pixel_0', 'qa_radsat_0','qa_pixel_1', 'qa_radsat_1', 'qa_pixel_2', 'qa_radsat_2']\n",
    "target = 'LST_Day_1km'\n",
    "landsat_res = 30 #m\n",
    "modis_res = 1000 #m\n",
    "radius = 16 #(33-1)/2 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3e2c2d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60d30b77ec4b4e6a86d06b368d0ed5f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[40, -100], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(Tâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "######################################################### Initiate a map #######################################################\n",
    "Map = geemap.Map()\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9503c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = ee.FeatureCollection(us_city_collection)\n",
    "target_city=cities.filter(ee.Filter.eq('NAME10',city_num))\n",
    "Map.addLayer(target_city,{}, city_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9258410",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010-12-01 2011-03-01\n",
      "2011-03-01 2011-06-01\n",
      "2011-06-01 2011-09-01\n",
      "2011-09-01 2011-12-01\n",
      "2011-12-01 2012-03-01\n",
      "2012-03-01 2012-06-01\n",
      "2012-06-01 2012-09-01\n",
      "2012-09-01 2012-12-01\n",
      "2012-12-01 2013-03-01\n",
      "2013-03-01 2013-06-01\n",
      "2013-06-01 2013-09-01\n",
      "2013-09-01 2013-12-01\n",
      "2013-12-01 2014-03-01\n",
      "2014-03-01 2014-06-01\n",
      "2014-06-01 2014-09-01\n",
      "2014-09-01 2014-12-01\n",
      "2014-12-01 2015-03-01\n",
      "2015-03-01 2015-06-01\n",
      "2015-06-01 2015-09-01\n",
      "2015-09-01 2015-12-01\n",
      "2015-12-01 2016-03-01\n",
      "2016-03-01 2016-06-01\n",
      "2016-06-01 2016-09-01\n",
      "2016-09-01 2016-12-01\n",
      "2016-12-01 2017-03-01\n",
      "2017-03-01 2017-06-01\n",
      "2017-06-01 2017-09-01\n",
      "2017-09-01 2017-12-01\n",
      "2017-12-01 2018-03-01\n",
      "2018-03-01 2018-06-01\n",
      "2018-06-01 2018-09-01\n",
      "2018-09-01 2018-12-01\n",
      "2018-12-01 2019-03-01\n"
     ]
    }
   ],
   "source": [
    "start_date = datetime.date(2010, 12, 1)\n",
    "end_date = datetime.date(2019, 3, 1)\n",
    "delta = relativedelta(months=3)\n",
    "\n",
    "while start_date < end_date:\n",
    "    start = str(start_date)\n",
    "    end = str(start_date + delta)\n",
    "    print(start, end)\n",
    "    landsat = filter_collection(landsat_collection, start_date=start, end_date=end,geometry=target_city)\\\n",
    "            .map(rescale_rename_landsat).sort('CLOUD_COVER')\n",
    "    gap_filled_imgCol=get_gap_filled_image(landsat)\n",
    "    img_export=gap_filled_imgCol.select(predictors+qa_bands).median().reproject(landsat.first().projection()).unmask(-9999)\n",
    "    modis_reproj=preprocess_modis(modis_collection, start_date=start, end_date=end,geometry=target_city)\n",
    "    modis_reproj_list = modis_reproj.toList(modis_reproj.size())\n",
    "    for i in range(modis_reproj.size().getInfo()):\n",
    "        modis_download = ee.Image(modis_reproj_list.get(i))\n",
    "        vector=modis_download.sample(\n",
    "          region= target_city.geometry(),\n",
    "          dropNulls=False,\n",
    "          geometries=True,\n",
    "        )\n",
    "        fname=ee.Date(modis_download.get('system:time_start')).format(\"YYMMdd\").getInfo()\n",
    "#        print(fname)\n",
    "        export_to_drive(img = img_export, region = vector, radius = radius,\n",
    "                        units = 'pixels', scale = landsat_res, folder = drive_folder, fname = fname)\n",
    "    start_date += delta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295ba519",
   "metadata": {},
   "source": [
    "# Read a TFRecord file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4be22022",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfrecords2numpy import TFRecordsParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8fce27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=tf.data.TFRecordDataset(\n",
    "    '060306.tfrecord.gz', compression_type='GZIP', buffer_size=None, num_parallel_reads=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7c81777",
   "metadata": {},
   "outputs": [],
   "source": [
    "record=TFRecordsParser('060306.tfrecord').tfrecrods2numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52449cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3ea33036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2969"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3bf01d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b861b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (features, lst) in tqdm(enumerate(record), desc=\"Storing Files\", position=1, total=len(record), leave=False):\n",
    "    print(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "728cbc36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Blue', 'Green', 'Red']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bands=['Blue','Green','Red','NIR','SWIR1','SWIR2', 'ST', 'source_mask', 'qa_pixel_0', 'qa_radsat_0','qa_pixel_1', 'qa_radsat_1']\n",
    "bands=['Blue','Green','Red']\n",
    "feature_names=list(bands)\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e929780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target='LST_Day_1km'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "717eab56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Blue': FixedLenFeature(shape=[33, 33], dtype=tf.float32, default_value=None),\n",
      " 'Green': FixedLenFeature(shape=[33, 33], dtype=tf.float32, default_value=None),\n",
      " 'LST_Day_1km': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None),\n",
      " 'Red': FixedLenFeature(shape=[33, 33], dtype=tf.float32, default_value=None)}\n"
     ]
    }
   ],
   "source": [
    "# List of fixed-length features, all of which are float32.\n",
    "predictor_columns = [\n",
    "  tf.io.FixedLenFeature(shape=[33,33], dtype=tf.float32) for k in feature_names\n",
    "]\n",
    "target_columns = [\n",
    "  tf.io.FixedLenFeature(shape=[1], dtype=tf.float32)\n",
    "]\n",
    "\n",
    "# Dictionary with names as keys, features as values.\n",
    "features_dict = dict(zip(feature_names+[target], predictor_columns+target_columns))\n",
    "\n",
    "pprint(features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e15b7912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=2969>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count the number of examples in a TFRecord\n",
    "dataset.reduce(np.int64(0), lambda x, _: x + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f72066d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def input_fn(serialized_example):\n",
    "\n",
    " # Make a parsing function\n",
    "    example = tf.io.parse_single_example(serialized_example,features_dict)\n",
    "    return example\n",
    "  \n",
    "  # Passing of FeatureColumns to a 4D tensor\n",
    "#     def stack_images(features):         \n",
    "#         nfeat = tf.transpose(tf.squeeze(tf.stack(list(features.values()))))\n",
    "#         return nfeat\n",
    "  \n",
    "#     dataset = dataset.map(parse)\n",
    "#     dataset = dataset.map(stack_images)\n",
    "  \n",
    "#     if shuffle:\n",
    "#         dataset = dataset.shuffle(buffer_size = batchSize * 10)\n",
    "#     dataset = dataset.batch(batchSize)\n",
    "#     dataset = dataset.repeat(numEpochs)\n",
    "parsed_dataset= dataset.map(input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff19f47d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for elements in parsed_dataset.take(1):\n",
    "    print(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b829b04e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#rescale to 255\n",
    "display_num = 10\n",
    "plt.figure(figsize=(9, 40))\n",
    "\n",
    "c=0\n",
    "for i in range(5, display_num):\n",
    "    for x in parsed_dataset.take(i):\n",
    "        x\n",
    "    Red=x['Red'].numpy().clip(0,1)\n",
    "#    Red=(Red-Red.min())/(Red.max()-Red.min())\n",
    "    Green=x['Green'].numpy().clip(0,1)\n",
    "#    Green=(Green-Green.min())/(Green.max()-Green.min())\n",
    "    Blue=x['Blue'].numpy().clip(0,1)\n",
    "#    Blue=(Blue-Blue.min())/(Blue.max()-Blue.min())\n",
    "    LST=x[target].numpy()[0]\n",
    "#    tensor = tf.squeeze(x).numpy()\n",
    "#   #print(target.sum())  \n",
    "    plt.subplot(display_num, 2, c + 1)\n",
    "    plt.imshow(np.stack((Red,Green,Blue),-1))\n",
    "    plt.title(f'LST:{LST}')\n",
    "    c+=2 \n",
    "plt.savefig('TFRecord_vis')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
